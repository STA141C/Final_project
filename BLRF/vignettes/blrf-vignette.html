<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Yujia Lu, Yating Ge, Yuqing Yang" />


<title>Introduction to BLRF</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Introduction to BLRF</h1>
<h4 class="author">Yujia Lu, Yating Ge, Yuqing Yang</h4>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">library</span>(BLRF)</span></code></pre></div>
<div id="introduction-to-blrf" class="section level3">
<h3>1.1 Introduction to BLRF</h3>
<ul>
<li><p>This library combines bag of Little Bootstraps, also known as BLB, to replace the process of ordinary bootstrapping in the standard Random Forest algorithm in order to gain more robustness in prediction for random forest classification as well as regression.</p></li>
<li><p>Like its name implies, there are a large number of individual decision trees involved in the random forest. The trees work as an ensemble. Each individual tree in the random forest returns a prediction. Finally, the model’s prediction is determined by the most votes of all decision trees.</p></li>
<li><p>Regarding to ordinary random forest, say we have a training set of size N. Each individual tree randomly takes a random sample of size N with replacement. Through, ordinary bootstrapping is a powerful tool for approximating quantities, the method’s reliance on repeated resampling make it computationally intensive and ill-suited for extremely large date sets. Thus we introduce the Bag of Little Bootstraps (BLB) as an alternative approximation. The Bag of Little Bootstraps (BLB) implements a different way to bagging. BLB combines features of the bootstrap and subsampling to form a resampling method well-suited for computations on large data sets while maintaining the favorable statistical properties of the bootstrap (Kleiner et al., 2014).</p></li>
</ul>
</div>
<div id="internal-functions-hidden-functions-shipped-within-this-library" class="section level3">
<h3>1.2 Internal functions (hidden functions) shipped within this library</h3>
<table>
<colgroup>
<col width="16%"></col>
<col width="64%"></col>
<col width="18%"></col>
</colgroup>
<thead>
<tr class="header">
<th>function name</th>
<th>Description</th>
<th>Return value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>subsampling()</code></td>
<td>Sampling original data into s subsamples without replacement</td>
<td>list of subsamples</td>
</tr>
<tr class="even">
<td><code>weights()</code></td>
<td>Calculate weights of each observation in subsample</td>
<td>matrix of weights</td>
</tr>
<tr class="odd">
<td><code>one_tree()</code></td>
<td>Implement random forest once and return a one_tree object</td>
<td>one_tree object</td>
</tr>
<tr class="even">
<td><code>tree_implement()</code></td>
<td>Build Little Random Forest (LRS) for one subsample</td>
<td>LRS</td>
</tr>
<tr class="odd">
<td><code>Confusion_one_tree()</code></td>
<td>Calculate confusion matrix for each response variable for one tree</td>
<td>confusion_matrix</td>
</tr>
<tr class="even">
<td><code>residual_ci()</code></td>
<td>Calculate residual confidence interval for regression random forest</td>
<td>matrix</td>
</tr>
<tr class="odd">
<td><code>implement_check_input()</code></td>
<td>Checking if all inputs are valid for function <code>blrf()</code></td>
<td>True or False</td>
</tr>
<tr class="even">
<td><code>predict_check_input()</code></td>
<td>Checking if all inputs are valid for function <code>predict.blrf()</code></td>
<td>True or False</td>
</tr>
</tbody>
</table>
</div>
<div id="fit-little-random-forests-brlf" class="section level3">
<h3>1.3 Fit little random forests <code>brlf()</code></h3>
<ul>
<li><p>The method of <code>brlf()</code> function implements little random forests on the trainning dataset, returns a <code>brlf</code> object.</p></li>
<li><p>function <code>brlf()</code> : main parameters included in the function</p></li>
</ul>
<table>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Definition in BLRF</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>n</td>
<td>Size of training data set</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\gamma\)</span>(gamma)</td>
<td>The user-defined sizing factor that determinses value of b</td>
</tr>
<tr class="odd">
<td>s</td>
<td>Total number of Little Random Forests</td>
</tr>
<tr class="even">
<td>b</td>
<td>Number of distinct observations in each Little Forest, <span class="math inline">\(b = n^{\gamma}\)</span></td>
</tr>
<tr class="odd">
<td>r</td>
<td>Number of trees</td>
</tr>
<tr class="even">
<td>nvar</td>
<td>Number of variables(ramdonly subset) to subset to build one tree.</td>
</tr>
<tr class="odd">
<td>split</td>
<td>Can be “deviance” or “gini”. Default to be “gini”</td>
</tr>
<tr class="even">
<td>control</td>
<td>tree::tree.control</td>
</tr>
<tr class="odd">
<td>core</td>
<td>Number of core to used for parallel computing</td>
</tr>
</tbody>
</table>
<ul>
<li><code>brlf</code> object
<ul>
<li><p>when implement on random forest classification ,<code>brlf</code> object includes: <code>Tree_object$Trees</code>,<code>Tree_object$fitted_prob</code>,<code>Tree_object$fitted_label</code>,<code>Tree_object$accuracy_ci</code></p></li>
<li><p>when implement on random forest regression ,<code>brlf</code> object includes:<br />
<code>Tree_object$Trees</code>, <code>Tree_object$fitted</code>, <code>Tree_object$residuals</code>, <code>Tree_object$residuals_ci</code></p></li>
</ul></li>
</ul>
</div>
<div id="make-predictions-predict" class="section level3">
<h3>1.4 Make predictions <code>predict()</code></h3>
<ul>
<li><p>Random forest could be applied in both solving classification and regression problems. It operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. We implement methods so that to meet the requirements of different problem solving targets.</p></li>
<li><p>Classification：<code>predict()</code> is able to return predictions for labels or probabilities; able to return confidence interval for predicted probabilities. <code>accuracy_mean_ci()</code> is able to calculate overall average accuracy and the confidence interval of accuracy aggreating all Trees.</p></li>
<li><p>Reregssion：<code>predict()</code> is able to return predictions of regression; able to get the percentile confidence intervals for regression predictions.</p></li>
</ul>
</div>
<div id="example-of-little-random-forest-classification" class="section level3">
<h3>2.1 Example of Little Random Forest Classification</h3>
<div id="the-following-section-describes-how-to-use-the-library-for-random-forest-classification-problem." class="section level4">
<h4>The following section describes how to use the library for random forest classification problem.</h4>
<ul>
<li>Load data set ‘glass’ for classification, sample 75% for train set and 25% for test set<br />
reference : <a href="https://www.kaggle.com/uciml/glass/kernels" class="uri">https://www.kaggle.com/uciml/glass/kernels</a></li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="co">## load train data set and test data set for classification</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="kw">load</span>(<span class="st">&quot;../tinydata/train_glass_sample.Rda&quot;</span>)</span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="kw">load</span>(<span class="st">&quot;../tinydata/test_glass_sample.Rda&quot;</span>)</span>
<span id="cb2-4"><a href="#cb2-4"></a>test_glass_sample_x &lt;-<span class="st"> </span><span class="kw">subset</span>(test_glass_sample, <span class="dt">select =</span> <span class="op">-</span><span class="kw">c</span>(Type))</span>
<span id="cb2-5"><a href="#cb2-5"></a>test_glass_sample_y &lt;-<span class="st"> </span>test_glass_sample[<span class="kw">c</span>(<span class="st">&#39;Type&#39;</span>)]</span></code></pre></div>
<ul>
<li>Run <code>brlf()</code> to create little random forest object with multiple attributes; when <strong>core = 1</strong>, indicating without parallel computation;</li>
</ul>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="co">## run brlf() method, core = 1 without parallel computation</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>cls_blrf &lt;-<span class="st"> </span><span class="kw">blrf</span>(Type<span class="op">~</span>., train_glass_sample, <span class="dt">gamma=</span><span class="fl">0.5</span>, <span class="dt">b =</span> <span class="ot">NULL</span>, <span class="dt">s=</span><span class="dv">10</span>, <span class="dt">r=</span><span class="dv">100</span>, <span class="dt">n_var=</span><span class="dv">5</span>,  <span class="dt">core =</span> <span class="dv">1</span>)</span>
<span id="cb3-3"><a href="#cb3-3"></a></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="co">## attributes for brlf object</span></span>
<span id="cb3-5"><a href="#cb3-5"></a>cls_blrf<span class="op">$</span>Trees</span>
<span id="cb3-6"><a href="#cb3-6"></a>cls_blrf<span class="op">$</span>fitted_prob</span>
<span id="cb3-7"><a href="#cb3-7"></a>cls_blrf<span class="op">$</span>fitted_label</span>
<span id="cb3-8"><a href="#cb3-8"></a>cls_blrf<span class="op">$</span>accuracy_ci</span></code></pre></div>
<ul>
<li>Run <code>brlf()</code> to create little random forest objects with multiple attributes; when <strong>core = 4(or core &gt; 1)</strong>, indicating with parallel computation of 4 cores.</li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="co">## run brlf() method, core = 4 having parallel computation with core = 4</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>cls_blrf &lt;-<span class="st"> </span><span class="kw">blrf</span>(Type<span class="op">~</span>., train_glass_sample, <span class="dt">gamma=</span><span class="fl">0.5</span>, <span class="dt">b =</span> <span class="ot">NULL</span>, <span class="dt">s=</span><span class="dv">10</span>, <span class="dt">r=</span><span class="dv">200</span>, <span class="dt">n_var=</span><span class="dv">5</span>,  <span class="dt">core =</span> <span class="dv">4</span>)</span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="co">## attributes for brlf object</span></span>
<span id="cb4-4"><a href="#cb4-4"></a>cls_blrf<span class="op">$</span>Trees</span>
<span id="cb4-5"><a href="#cb4-5"></a>cls_blrf<span class="op">$</span>fitted_prob</span>
<span id="cb4-6"><a href="#cb4-6"></a>cls_blrf<span class="op">$</span>fitted_label</span>
<span id="cb4-7"><a href="#cb4-7"></a>cls_blrf<span class="op">$</span>accuracy_ci</span></code></pre></div>
<ul>
<li>Run <code>predict()</code> function to make predictions: <strong>set confidence = F, set probability = F, pretty = T</strong>, return predicted labels for data</li>
</ul>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="co">## make label prediction</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>y_label &lt;-<span class="st"> </span><span class="kw">predict</span>(cls_blrf, test_glass_sample_x, <span class="dt">confidence =</span> F, <span class="dt">probability =</span> F,<span class="dt">pretty =</span> T)</span>
<span id="cb5-3"><a href="#cb5-3"></a>y_label[[<span class="dv">1</span>]]</span>
<span id="cb5-4"><a href="#cb5-4"></a><span class="co">#&gt; [1] &quot;2&quot;</span></span></code></pre></div>
<ul>
<li>Run <code>predict()</code> function to make predictions: <strong>set confidence = F, probability = T, pretty = T</strong>, return predicted labels for data</li>
</ul>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a><span class="co">## make label prediction</span></span>
<span id="cb6-2"><a href="#cb6-2"></a>y_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(cls_blrf, test_glass_sample_x, <span class="dt">confidence =</span> F, <span class="dt">probability =</span> T,<span class="dt">pretty =</span> T)</span>
<span id="cb6-3"><a href="#cb6-3"></a>y_prob[<span class="dv">1</span>,]</span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="co">#&gt;          1          2          3          5          6          7 </span></span>
<span id="cb6-5"><a href="#cb6-5"></a><span class="co">#&gt; 0.31922542 0.39904253 0.07401699 0.06684584 0.02669984 0.11416939</span></span></code></pre></div>
<ul>
<li>Run <code>predict()</code> function to make predictions: <strong>set confidence = T, probability = T, pretty = F</strong>, return predicted labels for data</li>
</ul>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="co">## make label prediction</span></span>
<span id="cb7-2"><a href="#cb7-2"></a>y_prob_ci &lt;-<span class="st"> </span><span class="kw">predict</span>(cls_blrf, test_glass_sample_x, <span class="dt">confidence =</span> T, <span class="dt">probability =</span> T,<span class="dt">pretty =</span> F)</span>
<span id="cb7-3"><a href="#cb7-3"></a>y_prob_ci[<span class="dv">1</span>,]</span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="co">#&gt;      prob.1 ci.lwr.1  ci.upr.1    prob.2  ci.lwr.2 ci.upr.2     prob.3 ci.lwr.3</span></span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="co">#&gt; 2 0.3192254        0 0.7926934 0.3990425 0.1149335        1 0.07401699        0</span></span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="co">#&gt;    ci.upr.3     prob.5 ci.lwr.5  ci.upr.5     prob.6 ci.lwr.6  ci.upr.6    prob.7</span></span>
<span id="cb7-7"><a href="#cb7-7"></a><span class="co">#&gt; 2 0.3225806 0.06684584        0 0.3259203 0.02669984        0 0.1868487 0.1141694</span></span>
<span id="cb7-8"><a href="#cb7-8"></a><span class="co">#&gt;   ci.lwr.7  ci.upr.7</span></span>
<span id="cb7-9"><a href="#cb7-9"></a><span class="co">#&gt; 2        0 0.4204987</span></span></code></pre></div>
<ul>
<li>Run <code>accuracy_mean_ci()</code> to calculate overall average accuracy and the confidence interval of accuracy aggreating all Trees. Returan mean accuracy as well as confidence interval of accuracy for all y lables.</li>
</ul>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a>result &lt;-<span class="st"> </span><span class="kw">accuracy_mean_ci</span>(cls_blrf, test_glass_sample, <span class="dt">lower =</span> <span class="fl">0.025</span>, <span class="dt">upper =</span> <span class="fl">0.975</span>)</span>
<span id="cb8-2"><a href="#cb8-2"></a>result</span>
<span id="cb8-3"><a href="#cb8-3"></a><span class="co">#&gt;               1         2         3         5         6         7</span></span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="co">#&gt; mean  0.5353148 0.5539352 0.8451204 0.9219259 0.9255000 0.8058148</span></span>
<span id="cb8-5"><a href="#cb8-5"></a><span class="co">#&gt; 2.5%  0.3333333 0.2777778 0.4444444 0.3888889 0.9259259 0.4814815</span></span>
<span id="cb8-6"><a href="#cb8-6"></a><span class="co">#&gt; 97.5% 0.7777778 0.7222222 0.8703704 0.9629630 0.9259259 0.8518519</span></span></code></pre></div>
</div>
</div>
<div id="example-of-little-random-forest-regression" class="section level3">
<h3>2.2 Example of Little Random Forest Regression</h3>
<div id="the-following-section-describes-how-to-apply-this-library-for-random-forest-regression-." class="section level4">
<h4>The following section describes how to apply this library for random forest regression .</h4>
<ul>
<li>Load data set ‘mortality’ for regression, sample 75% for train set and 25% for test set</li>
<li>Mortality data set: the response variable (Mortality) was measured by the deaths per 100,000 population from all causes. Six independent variables were considered: annual precipitation, education, non-white, poverty, NOx and SO2.</li>
</ul>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a><span class="kw">load</span>(<span class="st">&quot;../tinydata/train_mortality_sample.Rda&quot;</span>)</span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="kw">load</span>(<span class="st">&quot;../tinydata/test_mortality_sample.Rda&quot;</span>)</span>
<span id="cb9-3"><a href="#cb9-3"></a>test_mortality_sample_x &lt;-<span class="st"> </span><span class="kw">subset</span>(test_mortality_sample, <span class="dt">select =</span> <span class="op">-</span><span class="kw">c</span>(MORTALITY))</span>
<span id="cb9-4"><a href="#cb9-4"></a>test_mortality_sample_y &lt;-<span class="st"> </span>test_mortality_sample[<span class="kw">c</span>(<span class="st">&#39;MORTALITY&#39;</span>)]</span></code></pre></div>
<ul>
<li>Run <code>brlf()</code> to create little random forest objects with multiple attributes; when <strong>core = 1</strong>, indicating without parallel computation</li>
</ul>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="co">## run brlf() method, core = 1 not having parallel computation with core = 4</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>rg_blrf &lt;-<span class="st"> </span><span class="kw">blrf</span>(MORTALITY<span class="op">~</span>., train_mortality_sample, <span class="dt">gamma=</span><span class="fl">0.6</span>, <span class="dt">b =</span> <span class="ot">NULL</span>, <span class="dt">s=</span><span class="dv">10</span>, <span class="dt">r=</span><span class="dv">100</span>, <span class="dt">n_var=</span><span class="dv">5</span>,  <span class="dt">core =</span> <span class="dv">1</span>)</span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="co">## attributes for brlf object</span></span>
<span id="cb10-4"><a href="#cb10-4"></a>rg_blrf<span class="op">$</span>attrs</span>
<span id="cb10-5"><a href="#cb10-5"></a>rg_blrf<span class="op">$</span>Trees</span>
<span id="cb10-6"><a href="#cb10-6"></a>rg_blrf<span class="op">$</span>fitted</span>
<span id="cb10-7"><a href="#cb10-7"></a>rg_blrf<span class="op">$</span>residuals</span>
<span id="cb10-8"><a href="#cb10-8"></a>rg_blrf<span class="op">$</span>residuals_ci</span></code></pre></div>
<ul>
<li>Run <code>brlf()</code> to create little random forest objects with multiple attributes; when <strong>core = 4(or core &gt; 1)</strong>, indicating with parallel computation of 4 cores.</li>
</ul>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="co">## run brlf() method, core = 4 having parallel computation with core = 4</span></span>
<span id="cb11-2"><a href="#cb11-2"></a>rg_blrf &lt;-<span class="st"> </span><span class="kw">blrf</span>(MORTALITY<span class="op">~</span>., train_mortality_sample, <span class="dt">gamma=</span><span class="fl">0.5</span>, <span class="dt">b =</span> <span class="ot">NULL</span>, <span class="dt">s=</span><span class="dv">10</span>, <span class="dt">r=</span><span class="dv">500</span>, <span class="dt">n_var=</span><span class="dv">5</span>,  <span class="dt">core =</span> <span class="dv">4</span>)</span>
<span id="cb11-3"><a href="#cb11-3"></a><span class="co">## attributes for brlf object</span></span>
<span id="cb11-4"><a href="#cb11-4"></a>rg_blrf<span class="op">$</span>attrs</span>
<span id="cb11-5"><a href="#cb11-5"></a>rg_blrf<span class="op">$</span>Trees</span>
<span id="cb11-6"><a href="#cb11-6"></a>rg_blrf<span class="op">$</span>fitted</span>
<span id="cb11-7"><a href="#cb11-7"></a>rg_blrf<span class="op">$</span>residuals</span>
<span id="cb11-8"><a href="#cb11-8"></a>rg_blrf<span class="op">$</span>residuals_ci</span></code></pre></div>
<ul>
<li>Run <code>predict()</code> function to make predictions: <strong>set confidence = F, probability = F, pretty = T</strong>, return regression predictions for data</li>
</ul>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a>y_pred &lt;-<span class="st"> </span><span class="kw">predict</span>(rg_blrf, test_mortality_sample_x, <span class="dt">confidence =</span> F, <span class="dt">probability =</span> F, <span class="dt">pretty =</span> T)</span>
<span id="cb12-2"><a href="#cb12-2"></a>y_pred[<span class="dv">1</span>]</span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="co">#&gt; [1] 948.757</span></span></code></pre></div>
<ul>
<li>Run <code>predict()</code> function to make predictions: <strong>set confidence = T, probability = F, pretty = F</strong>, return confidence interval for regression predictions for data</li>
</ul>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a>y_pred_ci &lt;-<span class="st"> </span><span class="kw">predict</span>(rg_blrf, test_mortality_sample_x, <span class="dt">confidence =</span> T, <span class="dt">probability =</span> F, <span class="dt">pretty =</span> T)</span>
<span id="cb13-2"><a href="#cb13-2"></a>y_pred_ci<span class="op">$</span>fit[<span class="dv">1</span>]</span>
<span id="cb13-3"><a href="#cb13-3"></a><span class="co">#&gt; [1] 948.757</span></span>
<span id="cb13-4"><a href="#cb13-4"></a>y_pred_ci<span class="op">$</span>ci[<span class="dv">1</span>]</span>
<span id="cb13-5"><a href="#cb13-5"></a><span class="co">#&gt; [1] [ 901.205702777778 , 993.983680555556 ]</span></span>
<span id="cb13-6"><a href="#cb13-6"></a><span class="co">#&gt; Levels: [ 901.205702777778 , 993.983680555556 ]</span></span></code></pre></div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
